#!/bin/bash

# print usage info
usage() {
    cat <<EOF
ryftrest is a ryftprim equivalent, it uses ryft-server as a backend.

Usage: $0 [options]

Search specific:
-h|--help          Prints this short help message.
-p|--mode=<mode>   Specifies the search mode to run, which can be one of:
                     - exact_search (or es) (used by default)
                     - fuzzy_hamming_search (or fhs)
                     - fuzzy_edit_distance_search (or feds)
                     - date_search (or ds)
                     - time_search (or ts)
                     - numeric_search (or ns) also used for currency
                     - ipv4_search (or ipv4)
                     - ipv6_search (or ipv6)
                     - pcre2_search (or pcre2)
-f|--file=<path>   Specifies an input filename.
-c|--catalog=<path> Specifies an input catalog name.
-i                 Specifies case-insensitive analysis for supported primitives.
-r|--reduce        Reduce the duplicates for FEDS (by default)
--no-reduce        Do not reduce the duplicates for FEDS
-n|--nodes=<N>     Specifies 1-4 RCAB processing nodes to use (default is 4).
-d|--fuzziness=<D> Specifies the fuzzy search distance.
-w|--width=<W>     Specifies the surrounding width.
--line             Specifies the surrounding whole line (the same as -w=line).
-e|--delimiter=<E> Specifies the delimiter used between found records.
                   For example pass Windows new line as -e $'\r\n'.
-s|-q=<query>      Specifies the search/query expression to use.
  |--query=<query>
-od|--data=<file>  Used to keep a data results file.
-oi|--index=<file> Used to keep an index results file.
-ov|--view=<file>  Used to keep a view results file. To speed up /search/show.
--lifetime=<T>     Used to automatically cleanup results files. Examples: 1h, 1m, 20s.
--backend=<X>      Used to select "ryftprim" or "ryftx" backend.

REST specific:
-a|--address=<addr> Specifies the ryft-server address.
                      "http://localhost:8765" by default.
-u|--user=<cred> Use user credentials, "username:password".
  |--auth
--search         Use /search endpoint to print all found items.
--count          Use /count endpoint instead of /search to print just statistics (default).
--dry|--dry-run  Do a "dry-run" (do not call Ryft hardware).
--limit=N        Specifies the limit on total number of records printed (used with /search).
--local          Specifies the local search. Opposite to --cluster. (default)
--cluster        Specifies the cluster search. Opposite to --local.
--format=<fmt>   Specifies format of the result records, can be:
                     - raw - base-64 encoded data, by default.
                     - xml - decode XML records
                     - json - decode JSON objects
                     - utf8 - for text search get utf-8 string
                              instead of base-64 encoded raw bytes
                     - null|none - ignores all data
--fields=<list>  Specifies comma-separated list of fields to return.
                 This parameter is useful with XML and JSON formats.
--transform=<tx> Specifies custom post-process transformation.
                 Should be one of:
                     - match("expr") - regexp to match "expr"
                     - replace("expr", "template") - regexp to replace
                     - script("name") - call an external script
                 Several transformations can be specified.
                 Can be provided multiple
--share-mode     Sharing mode. Can be "ignore", "skip" or "wait-10s".
--no-stats       Disable statistics output.
--stream         Use stream output format. Provides a sequence of JSON
                 "tag-object" pairs to be able to decode input data on the fly
                 (is used for node communication within cluster).
--performance    Add performance metrics to the output statistics.
--accept=<fmt>   Accept format can be "json" or "csv".

-v|--verbose     Tells curl to be verbose.
-vv|--pretty     Get pretty (properly indented) formatting with jq tool.
--drate          Reformat output to add Data Rate
--details        Reformat output to add Data Rate and details on intermediate results


Examples:

$0 -q 'Joe' -f '*.txt' -vv --search
  will search and print all 'Joe' occurences in text files.

$0 -q 'Joe' -f '*.txt' -vv --count
  will just print the number of matches and some performance numbers.

$0 -q '(RECORD.id CONTAINS "100310")' -f '*.pcrime' --format=xml --fields=ID,Date -vv
  will launch a structured search in pcrime files.
EOF
}

# print error message $1 and exit
fail() {
    echo "ERROR: $1"
    exit 1
}

# default values
MODE=
FILES=()
CATALOGS=()
CASE="true"
REDUCE=true
NODES=
FUZZINESS=
SURROUNDING=
DELIMITER=$'\r\n'
TRANSFORMS=()
SHARE_MODE=
QUERY=
DATA=
INDEX=
VIEW=
LIFETIME=
BACKEND=

ADDRESS=http://localhost:8765
AUTH_USER=
ENDPOINT=/count
DRYRUN=
LIMIT=
LOCAL=true
FORMAT=
FIELDS=
STATS=true
STREAM=
SPARK=
PERFORMANCE=
ACCEPT=json

# be silent by default

VERBOSE=-s
PRETTY=
ADD_DRATE=
ADD_DETAILS=
HIDE_HOSTNAME=true
#
# individual pieces jq formatting to add units of measurment for demo displays
#
UNITS1=' if .duration >= 1000 then
             {"Duration(sec)         ": ((.duration / 1000)|.*10+0.5|floor|./10)}
        else {"Duration(msec)        ": .duration}
        end
        + if .totalBytes >= 1099511627776 then
             {"Total Bytes(TB)       ": ((.totalBytes / 1024 / 1024 / 1024 / 1024)|.*100+0.005|floor|./100)}
        elif .totalBytes >= 1073741824 then
             {"Total Bytes(GB)       ": ((.totalBytes / 1024 / 1024 / 1024)|.*100+0.005|floor|./100)}
        elif .totalBytes >= 1048576 then
             {"Total Bytes(MB)       ": ((.totalBytes / 1024 / 1024)|.*100+0.005|floor|./100)}
        elif .totalBytes >= 1024 then
             {"Total Bytes(KB)       ": ((.totalBytes / 1024)|.*100+0.005|floor|./100)}
        else {"Total Bytes           ": .totalBytes}
        end'

UNITS_DR=' + if .dataRate >= 1024 then
             {"Data Rate(GB/s)       ": ((.dataRate / 1024)|.*100+0.005|floor|./100)}
        elif .dataRate < 0.001 then
             {"Data Rate(KB/s)       ": ((.dataRate * 1024)|.*100+0.005|floor|./100)}
        else {"Data Rate(MB/s)       ": (.dataRate |.*100+0.005|floor|./100)}
        end'

UNITS2=' + {"Matches               ": .matches}
        + if .fabricDataRate >= 1024 then
             {"Fabric Data Rate(GB/s)": ((.fabricDataRate / 1024)|.*100+0.005|floor|./100)}
        elif .fabricDataRate < 0.001 then
             {"Fabric Data Rate(KB/s)": ((.fabricDataRate * 1024)|.*100+0.005|floor|./100)}
        else {"Fabric Data Rate(MB/s)": .fabricDataRate}
        end
        + if .fabricDuration >= 1000 then
             {"Fabric Duration(sec)  ": ((.fabricDuration / 1000)|.*100+0.005|floor|./100)}
        else {"Fabric Duration(msec) ": .fabricDuration}
        end'

UNITS_H=' + {"Host                  ": .host}'

UNITS_H_DET=' + {"Host             ": .details.host}'

UNITS_1_DET=' + {"Duration         ": .details.duration}
              + {"Total Bytes      ": .details.totalBytes}'

UNITS_DR_DET=' + {"Data Rate        ": .details.dataRate}'

UNITS_2_DET=' + {"Matches          ": .details.matches}
              + {"Fabric Data Rate ": .details.fabricDataRate}
              + {"Fabric Duration  ": .details.fabricDuration}'

# parse options
while [[ $# > 0 ]]; do
    case "$1" in
    -p=*|--mode=*)
        MODE="${1#*=}"
        shift
        ;;
    -p|--mode)
        MODE="$2"
        shift 2
        ;;
    -f=*|--file=*)
        FILES=("${FILES[@]}" "${1#*=}")
        shift
        ;;
    -f|--file)
        FILES=("${FILES[@]}" "$2")
        shift 2
        ;;
    -c=*|--catalog=*)
        CATALOGS=("${CATALOGS[@]}" "${1#*=}")
        shift
        ;;
    -c|--catalog)
        CATALOGS=("${CATALOGS[@]}" "$2")
        shift 2
        ;;
    -i)
        CASE="false"
        shift
        ;;
    -r|--reduce)
        REDUCE="true"
        shift
        ;;
    --no-reduce)
        REDUCE="false"
        shift
        ;;
    -n=*|--nodes=*)
        NODES="${1#*=}"
        shift
        ;;
    -n|--nodes)
        NODES="$2"
        shift 2
        ;;
    -d=*|--fuzziness=*)
        FUZZINESS="${1#*=}"
        shift
        ;;
    -d|--fuzziness)
        FUZZINESS="$2"
        shift 2
        ;;
    -w=*|--width=*)
        SURROUNDING="${1#*=}"
        shift
        ;;
    -w|--width)
        SURROUNDING="$2"
        shift 2
        ;;
    --line)
        SURROUNDING="line"
        shift
        ;;
    -e=*|--delimiter=*)
        DELIMITER="${1#*=}"
        shift
        ;;
    -e|--delimiter)
        DELIMITER="$2"
        shift 2
        ;;
    -s=*|-q=*|--query=*)
        QUERY="${1#*=}"
        shift
        ;;
    -s|-q|--query)
        QUERY="$2"
        shift 2
        ;;
    -od=*|--data=*)
        DATA="${1#*=}"
        shift
        ;;
    -od|--data)
        DATA="$2"
        shift 2
        ;;
    -oi=*|--index=*)
        INDEX="${1#*=}"
        shift
        ;;
    -oi|--index)
        INDEX="$2"
        shift 2
        ;;
    -ov=*|--view=*)
        VIEW="${1#*=}"
        shift
        ;;
    -ov|--view)
        VIEW="$2"
        shift 2
        ;;
    --lifetime=*)
        LIFETIME="${1#*=}"
        shift
        ;;
    --lifetime)
        LIFETIME="$2"
        shift 2
        ;;
    --backend=*)
        BACKEND="${1#*=}"
        shift
        ;;
    --backend)
        BACKEND="$2"
        shift 2
        ;;
    -a=*|--address=*)
        ADDRESS="${1#*=}"
        shift
        ;;
    -a|--address)
        ADDRESS="$2"
        shift 2
        ;;
    -u=*|--user=*|--auth=*)
        AUTH_USER="${1#*=}"
        shift
        ;;
    -u|--user|--auth)
        AUTH_USER="$2"
        shift 2
        ;;
    --search)
        ENDPOINT="/search"
        shift
        ;;
    --count)
        ENDPOINT="/count"
        shift
        ;;
    --dry-run|--dry)
        DRYRUN="/dry-run"
        shift
        ;;
    --limit=*)
        LIMIT="${1#*=}"
        shift
        ;;
    --limit)
        LIMIT="$2"
        shift 2
        ;;
    --local)
        LOCAL="true"
        shift
        ;;
    --cluster)
        LOCAL="false"
        HIDE_HOSTNAME=
        shift
        ;;
    --format=*)
        FORMAT="${1#*=}"
        shift
        ;;
    --format)
        FORMAT="$2"
        shift 2
        ;;
    --fields=*)
        FIELDS="${1#*=}"
        shift
        ;;
    --fields)
        FIELDS="$2"
        shift 2
        ;;
    --transform=*)
        TRANSFORMS=("${TRANSFORMS[@]}" "${1#*=}")
        shift
        ;;
    --transform)
        TRANSFORMS=("${TRANSFORMS[@]}" "$2")
        shift 2
        ;;
    --share-mode=*)
        SHARE_MODE="${1#*=}"
        shift
        ;;
    --share-mode)
        SHARE_MODE="$2"
        shift 2
        ;;
    --no-stats)
        STATS="false"
        shift
        ;;
    --stream)
        STREAM="true"
        shift
        ;;
    --spark)
        SPARK="true"
        shift
        ;;
    --performance)
        PERFORMANCE="true"
        shift
        ;;
    --accept=*)
        ACCEPT="${1#*=}"
        shift
        ;;
    --accept)
        ACCEPT="$2"
        shift 2
        ;;
    -vv|--pretty)
        VERBOSE="-s" # tell curl to be silent
        PRETTY=true
        shift
        ;;
    -v|--verbose)
        VERBOSE="-v"
        PRETTY=""
        shift
        ;;
    --drate)
        VERBOSE="-s"
        PRETTY=true
        ADD_DRATE=true
        shift
        ;;
    --details)
        VERBOSE="-s" # tell curl to be silent
        PRETTY=true
        ADD_DETAILS=true
        shift
        ;;
    -h|--help)
        usage
        exit 0
        ;;
    *) # unknown option
        fail "'$1' is unknown option, run '$0 --help' for help"
        ;;
    esac
done

case "$ACCEPT" in
    csv)
        ACCEPT="Accept: text/csv"
        ;;
    json)
        ACCEPT="Accept: application/json"
        ;;
    msgpack)
        ACCEPT="Accept: application/msgpack"
        ;;
    *)
        fail "'$ACCEPT' is unknown accept mode, run '$0 --help' for help"
esac

[[ -z "$QUERY" ]] && fail "no search query provided, run '$0 --help' for help"
[[ -z "${FILES[@]}" && -z "${CATALOGS[@]}" ]] && fail "no file or catalog provided, run '$0 --help' for help"

# build the URL
URL_DATA=(--data-urlencode "local=$LOCAL")
[[ ! -z "$AUTH_USER" ]] && URL_DATA=("${URL_DATA[@]}" -u "$AUTH_USER")
[[ ! -z "$QUERY" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "query=$QUERY")
for file in "${FILES[@]}"; do
    [[ ! -z $file ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "files=$file")
done
for catalog in "${CATALOGS[@]}"; do
    [[ ! -z $catalog ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "catalog=$catalog")
done
[[ ! -z "$CASE" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "cs=$CASE")
[[ ! -z "$REDUCE" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "reduce=$REDUCE")
[[ ! -z "$NODES" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "nodes=$NODES")
[[ ! -z "$FUZZINESS" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "fuzziness=$FUZZINESS")
[[ ! -z "$SURROUNDING" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "surrounding=$SURROUNDING")
[[ ! -z "$DELIMITER" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "delimiter=$DELIMITER")
[[ ! -z "$MODE" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "mode=$MODE")
[[ ! -z "$LIMIT" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "limit=$LIMIT")
[[ ! -z "$DATA" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "data=$DATA")
[[ ! -z "$INDEX" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "index=$INDEX")
[[ ! -z "$VIEW" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "view=$VIEW")
[[ ! -z "$LIFETIME" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "lifetime=$LIFETIME")
[[ ! -z "$BACKEND" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "backend=$BACKEND")
[[ ! -z "$FORMAT" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "format=$FORMAT")
[[ ! -z "$FIELDS" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "fields=$FIELDS")
for tx in "${TRANSFORMS[@]}"; do
    [[ ! -z $tx ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "transform=$tx")
done
[[ ! -z "$SHARE_MODE" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "share-mode=$SHARE_MODE")
[[ ! -z "$STATS" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "stats=$STATS")
[[ ! -z "$STREAM" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "stream=$STREAM")
[[ ! -z "$SPARK" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "spark=$SPARK")
[[ ! -z "$PERFORMANCE" ]] && URL_DATA=("${URL_DATA[@]}" --data-urlencode "performance=$PERFORMANCE")

# check dependencies
[[ -z `which curl` ]] && fail "no curl found, run 'apt-get install curl' to install it"
[[ ! -z "$PRETTY" ]] && [[ -z `which jq` ]] && fail "no jq found, run 'apt-get install jq' to install it"

if [[ ! -z "$PRETTY" ]]; then
# setup jq filter based on user inputs
# check for query error; if local, remove hosts; if not dataRate, remove data rate; and normalize measurements
# Build up the filtering string
    if [[ -z "$ADD_DETAILS" ]]; then
        DETAILS="."
    else
        DETAILS=". +{details}"
    fi
    if [[ ! -z "$HIDE_HOSTNAME" ]]; then
        if [[ ! -z "$ADD_DRATE" ]]; then
            # Delete hostname, leave dataRate
            JQ_STR="${DETAILS} | .message // ( . | del(.host) | ${UNITS1} ${UNITS_DR} ${UNITS2}"
#            UNITS_DETAILS="${UNITS_1_DET} ${UNITS_DR_DET} ${UNITS_2_DET}"
        else
            # Delete hostname and dataRate
            JQ_STR="${DETAILS} | .message // ( . | del(.dataRate,.host) | ${UNITS1} ${UNITS2}"
#            UNITS_DETAILS="${UNITS_1_DET} ${UNITS_2_DET}"
        fi
    elif [[ -z "$ADD_DRATE" ]]; then
        JQ_STR="${DETAILS} | .message // ( . | del(.dataRate) | ${UNITS1} ${UNITS2} ${UNITS_H}"
#        UNITS_DETAILS="${UNITS_H_DET} ${UNITS_1_DET} ${UNITS_2_DET}"
    else
        JQ_STR="${DETAILS} | .message // ( . | ${UNITS1} ${UNITS_DR} ${UNITS2} ${UNITS_H}"
#        UNITS_DETAILS="${UNITS_H_DET} ${UNITS_1_DET} ${UNITS_DR_DET} ${UNITS_2_DET}"
    fi
    if [[ ! -z "$ADD_DETAILS" ]]; then
        JQ_STR="$JQ_STR | . +{details})"
    else
        JQ_STR="${JQ_STR})"
    fi
fi

# for "dry-run" always use jq .
if [[ ! -z "$DRYRUN" ]]; then
    PRETTY=true
    JQ_STR="."
fi

# do the search and print error/results
if [[ -z "$PRETTY" ]]; then
    # Flat output for feeding into other processes
    curl $VERBOSE --get "${URL_DATA[@]}" --compressed -H "$ACCEPT" "$ADDRESS$ENDPOINT$DRYRUN"
else
    # Prettified output without data rate or details
    curl $VERBOSE --get "${URL_DATA[@]}" --compressed -H "$ACCEPT" "$ADDRESS$ENDPOINT$DRYRUN" | jq "$JQ_STR"
fi
